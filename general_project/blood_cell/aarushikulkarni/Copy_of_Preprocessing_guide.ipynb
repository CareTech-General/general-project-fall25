{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxeN5l-K-vOJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- PREPROCESSING PARAMETERS  ----------\n",
        "METADATA_CSV = r\"\"  # path to metadata CSV\n",
        "IMAGE_DIR = r\".\"  # path to folder with images\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 16"
      ],
      "metadata": {
        "id": "5Rck21oj-yRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------- LOADING DATA ------ #\n",
        "\n",
        "# Load metadata and print first few rows\n",
        "def load_metadata(csv_path):\n",
        "    # Code here\n",
        "    df = read_csv(csv_path)\n",
        "    print(df.head())\n",
        "    return df\n",
        "\n",
        "# Split metadata into training and testing sets using train_test_split\n",
        "def split_metadata(df, label_col, test_size=0.2, random_state=42):\n",
        "    # Code here\n",
        "    X = df.drop(columns=[label_col])  # features\n",
        "    y = df[label_col]                 # labels\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
        "    )\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "ODdfsoCT-0Jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- PREPROCESSING FUNCTIONS ----------\n",
        "\n",
        "\n",
        "# Preprocess images: load, resize, normalize, and augment\n",
        "# 1. Load the image (you can use cv2.imread or keras.preprocessing.image.load_img)\n",
        "# 2. Resize it to img_size\n",
        "# 3. Convert to array and normalize (divide by 255.0)\n",
        "# 4. Return the preprocessed image\n",
        "def preprocess_images(image_dir, metadata_df, img_size):\n",
        "    # Code here\n",
        "    img = load_img(img_path, target_size=img_size)\n",
        "    # Convert to array\n",
        "    img_array = img_to_array(img)\n",
        "    # Normalize to [0,1]\n",
        "    img_array = img_array / 255.0\n",
        "    return img_array\n",
        "\n",
        "\n",
        "# Test out the image preprocessing by visualizing a few sample images\n",
        "def visualize_sample_images(generator, num_images=9):\n",
        "    # Code here\n",
        "    images, labels = next(generator)\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i])\n",
        "        label = \"Tumor\" if labels[i] > 0.5 else \"No Tumor\"\n",
        "        plt.title(label)\n",
        "        plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Preprocess all images in the dataframe\n",
        "# 1. Initialize empty lists for X (images) and y (labels)\n",
        "# 2. Loop through df rows:\n",
        "#     - Get image_id, build full path (e.g., os.path.join(image_dir, image_id + \".jpg\"))\n",
        "#     - Call preprocess_image() for each\n",
        "#     - Append image and label\n",
        "# 3. Convert lists to NumPy arrays and return\n",
        "def preprocess_all_images(df, image_dir, img_size):\n",
        "    # Code here\n",
        "    X, y = [], []\n",
        "    for _, row in df.iterrows():\n",
        "        img_path = os.path.join(image_dir, row['label'], os.path.basename(row['image_path']))\n",
        "        img_array = preprocess_image(img_path, img_size)\n",
        "        X.append(img_array)\n",
        "        y.append(1 if row['label'] == 'yes' else 0)\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    print(f\"Processed {len(X)} images. Shape: {X.shape}\")\n",
        "    return X, y\n",
        "\n",
        "# Create ImageDataGenerators for training and validation sets\n",
        "\n",
        "def create_datagens(train_df, val_df, base_dir, img_size, batch_size):\n",
        "    # Code here\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.1,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    # Only rescaling for validation\n",
        "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    # Flow from dataframe automatically loads and labels images\n",
        "    train_generator = train_datagen.flow_from_dataframe(\n",
        "        train_df,\n",
        "        x_col='image_path',\n",
        "        y_col='label',\n",
        "        directory=None,\n",
        "        target_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary',\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    val_generator = val_datagen.flow_from_dataframe(\n",
        "        val_df,\n",
        "        x_col='image_path',\n",
        "        y_col='label',\n",
        "        directory=None,\n",
        "        target_size=img_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode='binary',\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    return train_generator, val_generator\n",
        "\n"
      ],
      "metadata": {
        "id": "7F39mlI2-09d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}